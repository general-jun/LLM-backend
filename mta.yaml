_schema-version: 3.3.0
ID: llm-backend
description: Knowledge Management and Chat Service Using SAP AI Core
version: 1.0.0
parameters:
  enable-parallel-deployments: true
build-parameters:
  before-all:
  - builder: custom
    commands:
      - npm ci
      - npx cds build --production


#######################################################################
# - Deploy Location 
#   Subaccount -> Space -> Applications
modules:
#----------------------------------------------------------------------
# Description > OData servcie
- name: llm-backend-app
  type: nodejs
  path: gen/srv
  requires:
    - name: llm-db-svc
    - name: llm-xsuaa-svc
  provides:
    - name: srv-api
  properties:
      srv-url: ${default-url}
  parameters:
    buildpack: nodejs_buildpack
    disk-quota: 1024M
    memory: 512M
  build-parameters:
    builder: npm-ci
    ignore:
      - node_modules/
#----------------------------------------------------------------------
# Description > Database deployer
- name: llm-deployer-app
  type: hdb
  path: gen/db
  requires:
    - name: llm-db-svc
  parameters:
    buildpack: nodejs_buildpack
  build-parameters:
    ignore:
      - node_modules/


#######################################################################
# - Deploy Location
#   Subaccount -> Space -> Service Instances
resources:
#----------------------------------------------------------------------
# Type > Managed Approuter
- name: llm-xsuaa-svc
  type: org.cloudfoundry.managed-service
  parameters:
    service: xsuaa
    service-plan: application
    path: ./xs-security.json
    config:
      tenant-mode: dedicated
      xsappname: llm-auth-app

#----------------------------------------------------------------------
# Type > HDI Container
- name: llm-db-svc
  type: com.sap.xs.hdi-container
  parameters:
    service: hana
    service-plan: hdi-shared